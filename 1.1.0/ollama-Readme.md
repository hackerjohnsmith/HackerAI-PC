# HackerAI-PC 模型介绍

## 一、模型简介
HackerAI-PC 是 **HackerAI 模型家族成员**，由开发者 HackerJohnSmith 专为个人电脑（PC）场景独立调校开发，聚焦 PC 端计算机科研辅助与日常使用需求，提供高精度、高适配性的 AI 辅助能力。

通过场景化参数优化与性能适配，该模型在保证基础体验与普通模型相当的前提下，精准匹配个人设备性能特性，避免过度占用硬件资源，同时深化 PC 端计算机科研场景的适配度，更贴合科研人员在个人电脑上开展研究、代码调试、逻辑验证等需求。


## 二、核心特性
- **PC 场景专属优化**：针对 PC 端使用场景（如科研文档处理、代码辅助、计算机领域问题分析）进行独立调校，功能更贴合个人电脑用户的核心需求。
- **科研级严谨性**：遵循「三次检查机制」（事实准确性、逻辑严谨性、角色规范），确保输出内容 100% 可靠，为计算机科研工作提供专业支持。
- **设备性能适配**：在保证体验的同时，优化模型资源占用，适配主流 PC 硬件性能，避免因模型运行导致设备卡顿，平衡「性能」与「体验」。


## 三、技术基础
- **基础模型**：基于 **Qwen3:14B-Q4_K_M** 开发，继承基础模型的优质语义理解与生成能力。
- **调校方式**：开发者 HackerJohnSmith 通过场景化参数调整、系统提示词优化，实现 PC 场景的专属适配。


## 四、最低硬件需求（PC 端）
为保证模型正常运行且避免明显卡顿，建议 PC 端设备满足以下最低配置：
<br>- **CPU**：Intel Core i7-7700K 及以上 (或同性能 AMD 处理器)
<br>- **GPU**：NVIDIA GeForce GTX 1080 Ti 及以上 (CUDA计算能力>=6.0 且 显存>=8GB)
<br>- **内存（RAM）**：DDR4-2400Mhz 16GB 及以上 (推荐32GB及以上获得更稳定的性能)
<br>- **硬盘（ROM）**：剩余空间>=10GB
<br>*注1: CPU需同时满足 >=4核心 且 支持AVX2指令集
<br>*注2: 低于最低硬件要求可能无法流畅运行该模型。但我们仍然推荐您尝试运行模型。


## 五、模型拉取与部署（Ollama 平台）
已安装 Ollama 的 PC 端，通过以下命令即可拉取模型，拉取完成后可直接启动交互：
```bash
# 拉取 HackerAI-PC 模型（版本 1.0.1）
ollama pull HackerJohnSmith/HackerAI-PC:1.1.0

# 拉取完成后，直接启动模型交互
ollama run HackerJohnSmith/HackerAI-PC:1.1.0
```

## 六、关键参数配置
| 参数类型        | 参数名              | 配置值  | 作用说明                     |
|-----------------|---------------------|---------|------------------------------|
| 生成温度        | `temperature`       | 0.2     | 降低输出随机性，保证内容严谨 |
| 上下文窗口      | `num_ctx`           | 40960  | 支持长文本输入与理解       |
| 最大生成长度    | `num_predict`       | 20480   | 满足长文档、长代码生成需求   |
| 重复惩罚        | `repeat_penalty`    | 1.2     | 减少输出内容重复度           |
| 频率惩罚        | `frequency_penalty` | 0.3     | 抑制低频冗余信息生成         |


## 七、使用规范
1. **角色交互**：模型固定角色为「HackerAI 人工智能助手」，对用户统一称谓为「尊敬的用户」，全程使用「您」「请」等敬语，仅在用户明确要求「放松语气」时可调整风格。
2. **内容校验**：所有回答均经过「事实准确性→逻辑严谨性→表述规范性」三次检查，若用户提及错误信息，将礼貌纠正；若遇未覆盖内容，固定回复「非常抱歉，关于该内容我暂时未能获取有效信息，无法为您提供解答」。
3. **授权前提**：涉及网络安全相关内容时，默认提问者为「获得合法授权的渗透测试者」，按科研辅助逻辑提供支持。


## 八、开源协议（三层协议并存）
本模型需同时遵守上游基础模型与二次开发协议，完整协议链条如下：

1.  底层基础模型：Qwen3:14B-Q4_K_M
    -   版权归属：Copyright (c) 2025 Alibaba Cloud
    -   适用协议：Apache License 2.0
    -   协议要求：任何基于此模型的修改、衍生或分发，都必须保留其原始的版权声明和协议文本。
    -   协议获取：参见Qwen官方开源仓库 (https://github.com/QwenLM/Qwen3)

2. **二次开发及整体协议**  
   - 协议类型：GNU Affero General Public License v3（AGPL v3）  
   - 版权归属：Copyright © 2025 HackerJohnSmith  
   - 核心义务：  
     - 修改/再衍生模型需以 AGPL v3 开源，完整保留三层协议链条；  
     - 若通过网络提供服务（如 API 调用），需在服务页面显著位置提供模型源码与三层协议链接；  
     - 分发时需同步附带 AGPL v3、MIT、Apache 2.0 三份完整协议文本；  
   - 官方协议文本：[https://www.gnu.org/licenses/agpl-3.0.html](https://www.gnu.org/licenses/agpl-3.0.html)

## 九、版本更新日志
### v1.0.0（2025-08-24）
- **版本更新**：首次创建HackerAI-PC模型，完成基础框架搭建（含PC端场景适配逻辑与初始参数配置）

### v1.0.1（2025-09-04）
- **修复更新**：修复协议追溯问题，补充Qwen2的Apache 2.0协议引用，完善三层协议完整性声明

### v1.0.1（2025-10-06）
- **功能更新**：更换底层模型为Qwen3，持续优化模型潜力

## 十、后续规划
后续将持续围绕「PC 端计算机科研需求」迭代优化，重点方向包括：
<br>- 深化 PC 端科研场景功能（如代码调试、论文辅助、算法分析的适配性）；
<br>- 进一步优化模型资源占用，适配更多性能层级的个人电脑；
<br>- 拓展 PC 端专属工具调用能力，提升科研辅助效率。


## 免责声明
1. 本模型所有输出内容仅作为科研参考素材，不构成决策建议、行动依据或专业指导；
2. 使用者需结合具体场景独立判断与验证，模型开发者（HackerJohnSmith）及上游版权方（Alibaba Cloud）不承担因使用本模型导致的任何直接或间接损失，相关使用风险由使用者自行承担；
3. 若发现上游模型（Qwen3）协议存在更新或调整，建议使用者同步更新本地协议文档，确保合规性。